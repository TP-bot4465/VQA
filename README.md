# Visual Question Answering (VQA) with PyTorch

  

**TravelLens VQA** lÃ  má»™t há»‡ thá»‘ng trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘a phÆ°Æ¡ng thá»©c (Multi-modal AI), cÃ³ kháº£ nÄƒng hiá»ƒu vÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i ngÃ´n ngá»¯ tá»± nhiÃªn dá»±a trÃªn ná»™i dung cá»§a hÃ¬nh áº£nh Ä‘áº§u vÃ o. Dá»± Ã¡n táº­p trung vÃ o viá»‡c so sÃ¡nh hiá»‡u nÄƒng giá»¯a cÃ¡c kiáº¿n trÃºc CNN Backbone khÃ¡c nhau vÃ  Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a cÆ¡ cháº¿ Attention.

-----

##  Giá»›i thiá»‡u

BÃ i toÃ¡n **Visual Question Answering (VQA)** yÃªu cáº§u mÃ¡y tÃ­nh pháº£i káº¿t há»£p kiáº¿n thá»©c tá»« hai lÄ©nh vá»±c:

1.  **Thá»‹ giÃ¡c mÃ¡y tÃ­nh (Computer Vision):** Äá»ƒ hiá»ƒu ná»™i dung bá»©c áº£nh ("Trong áº£nh cÃ³ gÃ¬?", "MÃ u sáº¯c ra sao?").
2.  **Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP):** Äá»ƒ hiá»ƒu Ã½ Ä‘á»‹nh cá»§a cÃ¢u há»i.

Há»‡ thá»‘ng nÃ y nháº­n Ä‘áº§u vÃ o lÃ  má»™t bá»©c áº£nh vÃ  má»™t cÃ¢u há»i, sau Ä‘Ã³ Ä‘Æ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c nháº¥t tá»« bá»™ tá»« Ä‘iá»ƒn Ä‘Ã£ há»c.

-----

##  TÃ­nh nÄƒng ná»•i báº­t

  * **Äa dáº¡ng Backbone CNN:** Há»— trá»£ nhiá»u mÃ´ hÃ¬nh trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng áº£nh máº¡nh máº½:
      * **Pretrained Models:** MobileNetV2, ResNet50, EfficientNetB3.
      * **Custom Model:** Máº¡ng CNN tá»± xÃ¢y dá»±ng (4 blocks) Ä‘á»ƒ so sÃ¡nh hiá»‡u nÄƒng.
  * **Xá»­ lÃ½ ngÃ´n ngá»¯:** Sá»­ dá»¥ng máº¡ng **LSTM (Long Short-Term Memory)** káº¿t há»£p vá»›i Word Embedding Ä‘á»ƒ mÃ£ hÃ³a cÃ¢u há»i.
  * **CÆ¡ cháº¿ Attention:** TÃ­ch há»£p cÆ¡ cháº¿ Attention giÃºp mÃ´ hÃ¬nh táº­p trung vÃ o cÃ¡c vÃ¹ng áº£nh quan trá»ng liÃªn quan Ä‘áº¿n tá»« khÃ³a trong cÃ¢u há»i.
  * **End-to-End Pipeline:** Bao gá»“m quy trÃ¬nh tá»« tiá»n xá»­ lÃ½ dá»¯ liá»‡u, huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡ Ä‘áº¿n dá»± Ä‘oÃ¡n thá»±c táº¿.

-----

##  Kiáº¿n trÃºc MÃ´ hÃ¬nh

Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng dá»±a trÃªn cÆ¡ cháº¿ **Joint Embedding** (NhÃºng káº¿t há»£p):

1.  **Image Encoder:**
      * áº¢nh Ä‘áº§u vÃ o Ä‘Æ°á»£c Ä‘Æ°a qua máº¡ng CNN (vÃ­ dá»¥: ResNet50) Ä‘á»ƒ trÃ­ch xuáº¥t Feature Map.
      * Äáº§u ra lÃ  má»™t vector Ä‘áº·c trÆ°ng (Feature Vector).
2.  **Question Encoder:**
      * CÃ¢u há»i Ä‘Æ°á»£c mÃ£ hÃ³a thÃ nh cÃ¡c chá»‰ sá»‘ (tokens) vÃ  Ä‘Æ°a qua lá»›p Embedding.
      * Máº¡ng LSTM xá»­ lÃ½ chuá»—i vÃ  tráº£ vá» vector ngá»¯ cáº£nh.



3.  **Fusion (Káº¿t há»£p):**
      * Hai vector Ä‘áº·c trÆ°ng (áº¢nh & CÃ¢u há»i) Ä‘Æ°á»£c káº¿t há»£p thÃ´ng qua phÃ©p nhÃ¢n tá»«ng pháº§n tá»­ (**Element-wise Multiplication**).
4.  **Classifier:**
      * ÄÆ°a qua cÃ¡c lá»›p Fully Connected (FC), Dropout vÃ  hÃ m kÃ­ch hoáº¡t Tanh.
      * Lá»›p cuá»‘i cÃ¹ng sá»­ dá»¥ng Softmax Ä‘á»ƒ dá»± Ä‘oÃ¡n xÃ¡c suáº¥t cá»§a cÃ¢u tráº£ lá»i.

-----

## ğŸ“Š Káº¿t quáº£ Thá»±c nghiá»‡m

ChÃºng tÃ´i Ä‘Ã£ tiáº¿n hÃ nh thá»­ nghiá»‡m trÃªn táº­p dá»¯ liá»‡u kiá»ƒm thá»­ (Test Set) vá»›i cÃ¡c cáº¥u hÃ¬nh mÃ´ hÃ¬nh khÃ¡c nhau. DÆ°á»›i Ä‘Ã¢y lÃ  báº£ng tá»•ng há»£p káº¿t quáº£:

| STT | MÃ´ hÃ¬nh (Backbone) | CÆ¡ cháº¿ Attention | Accuracy (%) | F1-Score |
|:---:|:-------------------|:----------------:|:------------:|:--------:|
| 1   | **EfficientNetB3** | âœ… CÃ³            | **70.15%** | **0.6340** |
| 2   | ResNet50           | âœ… CÃ³            | 68.20%       | 0.6105   |
| 3   | MobileNetV2        | âœ… CÃ³            | 65.40%       | 0.5821   |
| 4   | Custom CNN         | âœ… CÃ³            | 60.50%       | 0.5210   |
| 5   | Custom CNN         | âŒ KhÃ´ng         | 58.10%       | 0.4980   |

**Nháº­n xÃ©t:**

  * **EfficientNetB3 + Attention** cho káº¿t quáº£ tá»‘t nháº¥t vá»›i Ä‘á»™ chÃ­nh xÃ¡c trÃªn 70%.
  * CÃ¡c mÃ´ hÃ¬nh Pretrained (ResNet, EfficientNet) vÆ°á»£t trá»™i hÆ¡n háº³n so vá»›i máº¡ng tá»± xÃ¢y dá»±ng.
  * Viá»‡c Ã¡p dá»¥ng **Attention** giÃºp cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh Custom CNN (tÄƒng tá»« 58.1% lÃªn 60.5%).

-----

##  Cáº¥u trÃºc Dá»¯ liá»‡u (JSON Format)

Há»‡ thá»‘ng yÃªu cáº§u dá»¯ liá»‡u Ä‘áº§u vÃ o tuÃ¢n thá»§ cáº¥u trÃºc JSON sau:

### 1\. File CÃ¢u há»i (`questions.json`)

Má»—i cÃ¢u há»i Ä‘Æ°á»£c liÃªn káº¿t vá»›i má»™t hÃ¬nh áº£nh thÃ´ng qua `image_id`.

```json
{
    "questions": [
        {
            "question_id": 1,
            "image_id": 101,
            "question": "Äá»‹a Ä‘iá»ƒm trong hÃ¬nh lÃ  gÃ¬?"
        },
        {
            "question_id": 2,
            "image_id": 101,
            "question": "áº¢nh nÃ y cÃ³ ngÆ°á»i khÃ´ng?"
        }
    ]
}
```

### 2\. File NhÃ£n (`annotations.json`)

Chá»©a cÃ¢u tráº£ lá»i chuáº©n (Ground Truth) dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n.

```json
{
    "annotations": [
        {
            "question_id": 1,
            "image_id": 101,
            "answers": [
                {
                    "answer": "Báº£o tÃ ng Chá»©ng tÃ­ch Chiáº¿n tranh",
                    "answer_confidence": "yes"
                }
            ],
            "multiple_choice_answer": "Báº£o tÃ ng Chá»©ng tÃ­ch Chiáº¿n tranh",
            "answer_type": "other"
        }
    ]
}
```

### 3\. Tá»« Ä‘iá»ƒn (Vocabularies)

ÄÆ°á»£c sinh ra tá»± Ä‘á»™ng trong quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½:

  * `question_vocabs.txt`: Danh sÃ¡ch toÃ n bá»™ tá»« vá»±ng trong táº­p cÃ¢u há»i.
  * `answer_vocabs.txt`: Danh sÃ¡ch cÃ¡c nhÃ£n (classes) Ä‘áº§u ra (One-hot encoding targets).

-----

##  CÃ i Ä‘áº·t & Sá»­ dá»¥ng

### 1\. YÃªu cáº§u há»‡ thá»‘ng

  * Python 3.8+
  * PyTorch, Torchvision
  * Numpy, Matplotlib, Pillow, Scikit-learn

CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:

```bash
pip install torch torchvision numpy matplotlib pillow scikit-learn
```

### 2\. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

Cháº¡y pháº§n Preprocessing trong notebook Ä‘á»ƒ resize áº£nh vÃ  táº¡o tá»« Ä‘iá»ƒn:

```python
# Resize áº£nh vá» 224x224
resize_images(input_dir, output_dir)
# Táº¡o file JSON vÃ  Vocab
process_data(...)
```

### 3\. Huáº¥n luyá»‡n (Training)

Lá»±a chá»n mÃ´ hÃ¬nh vÃ  báº¯t Ä‘áº§u huáº¥n luyá»‡n:

```python
# VÃ­ dá»¥ huáº¥n luyá»‡n vá»›i ResNet50
model = VQAModel(resnet, ..., with_att=True)
train(model, train_loader, valid_loader, criterion, optimizer, device, num_epochs=50)
```

### 4\. Kiá»ƒm thá»­ (Inference)

Dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i cho má»™t áº£nh báº¥t ká»³:

```python
image_path = "path/to/image.png"
implement(model, image_path, ques_vocab, ans_vocab, transform, device)
```

-----

